# Neuro-evolution Deep Reinforcement Learning

NEDRL is a project that 
1. reproduce the results of the ["Deep Neuroevolution: Genetic Algorithms Are a Competitive Alternative for Training Deep Neural Networks for Reinforcement Learning"](https://arxiv.org/abs/1712.06567)
2. try to apply the paper method on other RL environment

## Branches

This project has 5 branches:

- master - the main branch.
- frostbite - the all environment + code + results of the reproduction of the paper. you will find the results in the results folder.
- cube1
- cube2
- cube3

the cube branches are the three different ways we tried to apply the NEDRL algorithm on an Rubics Cube gym environment.

for switching between branches please run
```bash
git checkout {$branch}
```

## Used Libraries
Here is a list of all projects and libraries we used in our project:

- [gym-Rubiks-Cube](https://github.com/RobinChiu/gym-Rubiks-Cube)
- [MagicCube](https://github.com/davidwhogg/MagicCube)
- [neuroevo paper](https://towardsdatascience.com/paper-repro-deep-neuroevolution-756871e00a66)
- [neuroevo github](https://github.com/AdrienLE/neuroevo)
- [rubiks_cube_convnet](https://github.com/jerpint/rubiks_cube_convnet)
- [Stock-Trading-Environment](https://github.com/notadamking/Stock-Trading-Environment)
- [gym openAI](https://gym.openai.com/)
- [openAI](https://openai.com/)

## Project Creators
- Itai Schwed
- Aviva Shneor Simchon
## License
[MIT](https://choosealicense.com/licenses/mit/)
